{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3btnXpFJOm8",
        "outputId": "b9ebca77-f1ec-4159-cd41-010fc0341d55"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/AI/polus\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43LjQ8QTSvDU",
        "outputId": "84cfb143-acf1-4dc9-a261-1dab1c086595"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/AI/polus\n",
            " dataset       data.yaml   exp5   __MACOSX   obj.names\t  zoloto_hack.ipynb\n",
            " dataset.zip   exp2\t   exp6   obj.data   yolo.ipynb  '–í–∏–¥–µ–æ –∫–æ–Ω–≤–µ–∏ÃÜ–µ—Ä–∞.rar'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏"
      ],
      "metadata": {
        "id": "q95Kkx7YrV8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sahi -qqqq"
      ],
      "metadata": {
        "id": "Jy4mi7tdI_wE"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "import re\n",
        "import random\n",
        "import json\n",
        "\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision.utils import draw_bounding_boxes\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pycocotools.coco import COCO\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sahi.utils.coco import Coco, CocoCategory, CocoImage, CocoAnnotation\n",
        "from sahi.utils.file import save_json"
      ],
      "metadata": {
        "id": "tGYGnr0WrbYm"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install pyyaml==5.1\n",
        "import sys, os, distutils.core\n",
        "# Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities.\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions\n",
        "!git clone 'https://github.com/facebookresearch/detectron2'\n",
        "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
        "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n",
        "sys.path.insert(0, os.path.abspath('./detectron2'))\n",
        "\n",
        "# Properly install detectron2. (Please do not install twice in both ways)\n",
        "# !python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ],
      "metadata": {
        "id": "juo60lqBk_31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "from detectron2.data.datasets import register_coco_instances,load_coco_json"
      ],
      "metadata": {
        "id": "tvII6v34lHUs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –î–∞—Ç–∞"
      ],
      "metadata": {
        "id": "CFtLsTAdrgw1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IROnr90AhZU"
      },
      "outputs": [],
      "source": [
        "!wget -O dataset.zip http://77.244.221.121/dataset.zip\n",
        "!unzip dataset.zip -d /content"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check (h, w) in directory"
      ],
      "metadata": {
        "id": "BKR2WRRhqRif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h, w = set(), set()\n",
        "public_paths = glob.glob('/content/dataset/public/*.jpg')\n",
        "for path in public_paths:\n",
        "    hi, wi, _ = cv2.imread(path).shape\n",
        "    h.add(hi)\n",
        "    w.add(wi)\n",
        "h, w"
      ],
      "metadata": {
        "id": "xI95D2ZfqUex",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ab9cb19-f0ad-4d58-8701-787d2599f584"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({720}, {1280})"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Merge train and test annotations"
      ],
      "metadata": {
        "id": "kNCLZaQHqD9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "train = json.load(open('/content/dataset/annot_local/train_annotation.json', 'r'))\n",
        "test = json.load(open('/content/dataset/annot_local/test_annotation.json', 'r'))\n",
        "\n",
        "anno = {}\n",
        "anno['licenses'] = train['licenses']\n",
        "anno['info'] = train['info']\n",
        "anno['categories'] = train['categories']\n",
        "anno['images'] = []\n",
        "anno['annotations'] = []\n",
        "\n",
        "MAX_TRAIN_ID = max(set([x['id'] for x in train['images']]))\n",
        "for x in test['images']:\n",
        "    x['height'] = 720 # height in train annotations\n",
        "    x['width'] = 1280 # width in train annotations\n",
        "    x['id'] = x['id'] + (MAX_TRAIN_ID * 1000) # —á—Ç–æ–±—ã –∞–π–¥–∏ –Ω–µ –ø–µ—Ä–µ—Å–µ–∫–∞–ª–∏—Å—å\n",
        "    anno['images'].append(x)\n",
        "\n",
        "for x in train['images']: \n",
        "    anno['images'].append(x)\n",
        "\n",
        "for x in test['annotations']:\n",
        "    del x['iscrowd']\n",
        "    x['image_id'] = x['image_id'] + (MAX_TRAIN_ID * 1000) # —á—Ç–æ–±—ã –∞–π–¥–∏ –Ω–µ –ø–µ—Ä–µ—Å–µ–∫–∞–ª–∏—Å—å\n",
        "    x['id'] = x['id'] + (MAX_TRAIN_ID * 1000) # —á—Ç–æ–±—ã –∞–π–¥–∏ –Ω–µ –ø–µ—Ä–µ—Å–µ–∫–∞–ª–∏—Å—å\n",
        "    anno['annotations'].append(x)\n",
        "\n",
        "for x in train['annotations']:\n",
        "    anno['annotations'].append(x)\n",
        "\n",
        "json.dump(anno, open('/content/dataset/annot_local/traintest_annotation.json', 'w'))"
      ],
      "metadata": {
        "id": "rx-qOmSAqFyG"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!du -sh dataset/annot_local/*"
      ],
      "metadata": {
        "id": "c8AKHAhUqHXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert COCO to YOLO format"
      ],
      "metadata": {
        "id": "GG6rL38utlRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_yolo_anno(train_paths, valid_paths):\n",
        "    coco = COCO('/content/dataset/annot_local/traintest_annotation.json')\n",
        "    ids = list(sorted(coco.imgs.keys()))\n",
        "\n",
        "    for i in tqdm(range(len(ids))):\n",
        "        img_id = ids[i]\n",
        "        ann_ids = coco.getAnnIds(imgIds=img_id)\n",
        "        path = coco.loadImgs(img_id)[0]['file_name']\n",
        "        anno_path = path.split('.')[0] + '.txt'\n",
        "        coco_annotation = coco.loadAnns(ann_ids)\n",
        "\n",
        "        boxes = []\n",
        "        num_objs = len(coco_annotation)\n",
        "\n",
        "        try:\n",
        "            for i in range(num_objs):\n",
        "                xmin = coco_annotation[i]['bbox'][0]\n",
        "                ymin = coco_annotation[i]['bbox'][1]\n",
        "                xmax = xmin + coco_annotation[i]['bbox'][2]\n",
        "                ymax = ymin + coco_annotation[i]['bbox'][3]\n",
        "                boxes.append([xmin, ymin, xmax, ymax])\n",
        "        except:\n",
        "            pass\n",
        "        \n",
        "        rows = []\n",
        "        for box in boxes:\n",
        "            label_index = 0\n",
        "            x_center = int((box[0] + box[2]) / 2)\n",
        "            y_center = int((box[1] + box[3]) / 2)\n",
        "            bbox_w = box[2] - box[0]\n",
        "            bbox_h = box[3] - box[1]\n",
        "            width = coco.loadImgs(img_id)[0]['width']\n",
        "            height = coco.loadImgs(img_id)[0]['height']\n",
        "            bbox_w = bbox_w / width\n",
        "            bbox_h = bbox_h / height\n",
        "            x_center = x_center / width\n",
        "            y_center = y_center / height\n",
        "            rows.append([label_index, x_center, y_center, bbox_w, bbox_h])\n",
        "\n",
        "        txt_path = '/content/yolo_dataset/obj_train_data/' if path in train_paths else '/content/yolo_dataset/obj_valid_data/'\n",
        "        txt_path += anno_path\n",
        "        with open(txt_path, 'w') as f:\n",
        "            for row in rows:\n",
        "                f.write(' '.join(list(map(str, row))) + '\\n')\n",
        "\n",
        "\n",
        "    yolo_train, yolo_valid = [], []\n",
        "    for path in train_paths:\n",
        "        yolo_path = '/content/yolo_dataset/obj_train_data/' + path\n",
        "        shutil.copy('/content/dataset/train/' + path, yolo_path)\n",
        "        yolo_train.append(yolo_path)\n",
        "\n",
        "    for path in valid_paths:\n",
        "        yolo_path = '/content/yolo_dataset/obj_valid_data/' + path\n",
        "        shutil.copy('/content/dataset/train/' + path, yolo_path)\n",
        "        yolo_valid.append(yolo_path)\n",
        "\n",
        "    with open('/content/yolo_dataset/train.txt', 'w') as f:\n",
        "        f.write(\"\\n\".join(yolo_train))\n",
        "\n",
        "    with open('/content/yolo_dataset/valid.txt', 'w') as f:\n",
        "        f.write(\"\\n\".join(yolo_valid))\n",
        "    \n",
        "    shutil.copy('/content/drive/MyDrive/AI/polus/obj.data', '/content/yolo_dataset/obj.data')\n",
        "    shutil.copy('/content/drive/MyDrive/AI/polus/obj.names', '/content/yolo_dataset/obj.names')"
      ],
      "metadata": {
        "id": "wmsz8-Qx48DA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## YOLOv5"
      ],
      "metadata": {
        "id": "7CU_LnfffEAG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SETUP"
      ],
      "metadata": {
        "id": "NdZEXSoKXS9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "%%capture\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "!cd yolov5 && pip install -r requirements.txt "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWMYFz5QU9kN",
        "outputId": "f718347e-2982-4f4f-9c07-f38f6d70438b"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "UsageError: Line magic function `%%capture` not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cp /content/drive/MyDrive/AI/polus/data.yaml /content/yolov5/data.yaml\n",
        "\n",
        "import yaml\n",
        "import io\n",
        "\n",
        "with open(\"/content/yolov5/data.yaml\", 'r') as stream:\n",
        "    data_loaded = yaml.safe_load(stream)\n",
        "\n",
        "data_loaded[\"train\"] = \"/content/yolo_dataset/obj_train_data/\"\n",
        "data_loaded[\"val\"] = \"/content/yolo_dataset/obj_valid_data/\"\n",
        "\n",
        "with io.open('/content/yolov5/data.yaml', 'w', encoding='utf8') as outfile:\n",
        "    yaml.dump(data_loaded, outfile, default_flow_style=False, allow_unicode=True)"
      ],
      "metadata": {
        "id": "8BCD2FzFfSsF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "U4q5mh_vXV-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/yolov5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ot80xQyj-4sX",
        "outputId": "3d9cd150-fafa-4ef2-aa6e-b2c7a13941fa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "all_paths = np.array(os.listdir('/content/dataset/train/'))"
      ],
      "metadata": {
        "id": "kUsyjnt9b8-3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kf = KFold(n_splits=5)\n",
        "for n_split in range(1, 2):\n",
        "    shutil.rmtree('/content/yolo_dataset/')\n",
        "    os.mkdir('/content/yolo_dataset/')\n",
        "    os.mkdir('/content/yolo_dataset/obj_train_data/')\n",
        "    os.mkdir('/content/yolo_dataset/obj_valid_data/')\n",
        "\n",
        "    for i, (train_index, test_index) in enumerate(kf.split(all_paths)):\n",
        "        if n_split == i + 1:\n",
        "            train_paths, valid_paths = all_paths[train_index], all_paths[test_index]\n",
        "    \n",
        "    create_yolo_anno(train_paths, valid_paths)\n",
        "len(train_paths), len(valid_paths)"
      ],
      "metadata": {
        "id": "AAq9xzCPb7Th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 1280 --batch 4 --epochs 20 --data data.yaml \\\n",
        "                --weights yolov5x6.pt --cache"
      ],
      "metadata": {
        "id": "PJbWt5sD-7Qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kf = KFold(n_splits=5)\n",
        "for n_split in range(2, 3):\n",
        "    shutil.rmtree('/content/yolo_dataset/')\n",
        "    os.mkdir('/content/yolo_dataset/')\n",
        "    os.mkdir('/content/yolo_dataset/obj_train_data/')\n",
        "    os.mkdir('/content/yolo_dataset/obj_valid_data/')\n",
        "\n",
        "    for i, (train_index, test_index) in enumerate(kf.split(all_paths)):\n",
        "        if n_split == i + 1:\n",
        "            train_paths, valid_paths = all_paths[train_index], all_paths[test_index]\n",
        "    \n",
        "    create_yolo_anno(train_paths, valid_paths)\n",
        "len(train_paths), len(valid_paths)"
      ],
      "metadata": {
        "id": "4EifqnWZch1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 1280 --batch 4 --epochs 20 --data data.yaml \\\n",
        "                --weights yolov5x6.pt --cache"
      ],
      "metadata": {
        "id": "mewxgyl_clCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kf = KFold(n_splits=5)\n",
        "for n_split in range(3, 4):\n",
        "    shutil.rmtree('/content/yolo_dataset/')\n",
        "    os.mkdir('/content/yolo_dataset/')\n",
        "    os.mkdir('/content/yolo_dataset/obj_train_data/')\n",
        "    os.mkdir('/content/yolo_dataset/obj_valid_data/')\n",
        "\n",
        "    for i, (train_index, test_index) in enumerate(kf.split(all_paths)):\n",
        "        if n_split == i + 1:\n",
        "            train_paths, valid_paths = all_paths[train_index], all_paths[test_index]\n",
        "    \n",
        "    create_yolo_anno(train_paths, valid_paths)\n",
        "len(train_paths), len(valid_paths)"
      ],
      "metadata": {
        "id": "SdIK_vZLcmPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 1280 --batch 4 --epochs 20 --data data.yaml \\\n",
        "                --weights yolov5x6.pt --cache"
      ],
      "metadata": {
        "id": "KwIXtsnScoXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference"
      ],
      "metadata": {
        "id": "QFhqTkMMdCwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/yolov5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0N_JVu2NdPr",
        "outputId": "3067cda3-b9b3-492f-9442-002c849cc958"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "public_paths = sorted(glob.glob('/content/dataset/public/*.jpg'))"
      ],
      "metadata": {
        "id": "ZK0IFukEbCFX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! python detect.py --weights runs/train/exp14/weights/best.pt runs/train/exp11/weights/best.pt \\\n",
        "                                                            /content/drive/MyDrive/AI/polus/experiments/exp7/weights/best.pt \\\n",
        "                                                            /content/drive/MyDrive/AI/polus/experiments/exp8/weights/best.pt \\\n",
        "                                                            /content/drive/MyDrive/AI/polus/experiments/exp9/weights/best.pt \\\n",
        "                                                    --img 1280 \\\n",
        "                                                    --source /content/dataset/public/ \\\n",
        "                                                    --augment \\\n",
        "                                                    --conf-thres 0.05 \\\n",
        "                                                    --save-txt --save-conf "
      ],
      "metadata": {
        "id": "uVLCoyvP0ecU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_soliton_labels_df(path_to_txt_folder):\n",
        "    simple_solution = []\n",
        "    for detection_file in os.listdir(path_to_txt_folder):\n",
        "        img_name = detection_file.split('.')[0] + '.jpg'\n",
        "        with open(path_to_txt_folder + detection_file, 'r') as f:\n",
        "            data = f.read()\n",
        "            data = [i for i in data.split('\\n') if i != '']\n",
        "        for line in data:\n",
        "            val = [float(i) for i in line.split()]\n",
        "            cls, xywh, conf = val[0], val[1:5], val[5]\n",
        "            center_x, center_y, width, height = xywh\n",
        "            xmin = center_x - (width / 2)\n",
        "            xmax = center_x + (width / 2)\n",
        "            ymin = center_y - (height / 2)\n",
        "            ymax = center_y + (height / 2)\n",
        "            simple_solution.append([img_name, cls, conf, xmin, xmax, ymin, ymax])\n",
        "    return simple_solution\n",
        "\n",
        "simple_solution = get_soliton_labels_df('runs/detect/exp19/labels/')\n",
        "simple_solution = pd.DataFrame(simple_solution, columns=['ImageID', 'LabelName', 'Conf', 'XMin', 'XMax', 'YMin', 'YMax'])\n",
        "simple_solution.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkUfpPUsPebW",
        "outputId": "b136d377-99b2-4166-9449-3f1d5984689a"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6422, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coco = Coco()\n",
        "coco.add_category(CocoCategory(id=0, name='stone0'))\n",
        "coco.add_category(CocoCategory(id=1, name='stone1'))\n",
        "\n",
        "for path in tqdm(sorted(simple_solution['ImageID'].unique())):\n",
        "    file_name = path\n",
        "    image_id = int(re.findall(r'\\d+', file_name)[0])\n",
        "    coco_image = CocoImage(file_name=file_name, height=1080, width=1920, id=image_id)\n",
        "    \n",
        "    boxes = simple_solution[simple_solution['ImageID'] == file_name][['XMin', 'XMax', 'YMin', 'YMax']].values\n",
        "\n",
        "    preds = []\n",
        "    for result in boxes:\n",
        "        xmin, xmax, ymin, ymax = result[0], result[1], result[2], result[3]\n",
        "        xmin = int(xmin * 1280)\n",
        "        ymin = int(ymin * 720)\n",
        "        xmax = int(xmax * 1280)\n",
        "        ymax = int(ymax * 720)\n",
        "        preds.append([xmin, ymin, xmax, ymax])\n",
        "    \n",
        "    for box in preds:\n",
        "        x_min = int(box[0])\n",
        "        y_min = int(box[1])\n",
        "        width = int(box[2] - x_min)\n",
        "        height = int(box[3]- y_min)\n",
        "        coco_image.add_annotation(\n",
        "            CocoAnnotation(\n",
        "            bbox=[x_min, y_min, width, height],\n",
        "            category_id=1,\n",
        "            category_name='stone1',\n",
        "            image_id=image_id\n",
        "            )\n",
        "        )\n",
        "    coco.add_image(coco_image)\n",
        "\n",
        "save_json(data=coco.json, save_path='kramarenko.json')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btsuSyZ3FI8W",
        "outputId": "e86aed2c-70b5-4083-e54b-09189658ca9f"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:01<00:00, 145.33it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Custom inference"
      ],
      "metadata": {
        "id": "yeAAvLr3nN2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yolo_paths = ['runs/train/exp7/weights/best.pt', 'runs/train/exp8/weights/best.pt', 'runs/train/exp9/weights/best.pt']\n",
        "detectron_predictors = [predictor]\n",
        "yolo_models = [torch.hub.load('ultralytics/yolov5', 'custom', path=path) for path in yolo_paths]"
      ],
      "metadata": {
        "id": "oIgSmMMOTBBo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3763907c-4e15-4dfa-e9c7-ebae5345e1c3"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 üöÄ 2022-10-15 Python-3.7.14 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 416 layers, 139970872 parameters, 0 gradients, 207.9 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ensemble-boxes -qqq"
      ],
      "metadata": {
        "id": "UoUV6yxSdV3g"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ensemble_boxes import *\n",
        "\n",
        "img = '/content/dataset/public/frame1335.jpg'\n",
        "\n",
        "yolo_models = []\n",
        "weights = [1] * (len(yolo_models) + 1)\n",
        "\n",
        "iou_thr = 0.5\n",
        "skip_box_thr = 0.0001\n",
        "sigma = 0.1\n",
        "\n",
        "def ensemble_results(img, yolo_models, predictor):\n",
        "    boxes_list, scores_list = [], []\n",
        "    labels_list = []\n",
        "    for model in yolo_models:\n",
        "        results = model(img)\n",
        "        pred = results.xyxy[0].detach().cpu()\n",
        "        for i in range(len(pred)):\n",
        "            pred[i][0] = pred[i][0] / 1280\n",
        "            pred[i][2] = pred[i][2] / 1280\n",
        "\n",
        "            pred[i][1] = pred[i][1] / 720\n",
        "            pred[i][3] = pred[i][3] / 720\n",
        "        boxes_list.append([x[:4].tolist() for x in pred])\n",
        "        scores_list.append([x[4].tolist() for  x in pred])\n",
        "        labels_list.append([1] * pred.shape[0])\n",
        "    \n",
        "    pred = predictor(cv2.imread(img))['instances']\n",
        "    bboxes = pred.pred_boxes.tensor.cpu().tolist()\n",
        "    for i in range(len(bboxes)):\n",
        "        bboxes[i][0] = bboxes[i][0] / 1280\n",
        "        bboxes[i][2] = bboxes[i][2] / 1280\n",
        "\n",
        "        bboxes[i][1] = bboxes[i][1] / 720\n",
        "        bboxes[i][3] = bboxes[i][3] / 720\n",
        "    dscores = pred.scores.cpu().tolist()\n",
        "    dlabels = pred.pred_classes.cpu().tolist()\n",
        "    dlabels = [1] * len(dlabels)\n",
        "\n",
        "    boxes_list.append(bboxes)\n",
        "    scores_list.append(dscores)\n",
        "    labels_list.append(dlabels)\n",
        "\n",
        "    boxes, scores, labels = weighted_boxes_fusion(boxes_list, scores_list, labels_list, weights=weights, iou_thr=iou_thr, skip_box_thr=skip_box_thr)\n",
        "    return boxes\n",
        "\n",
        "ensemble_results(img, yolo_models, predictor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzJYqZhRP-7g",
        "outputId": "2db80c07-2c9e-4410-ab21-4cdc477afa9e"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0.32008092403411864, 0.8573137919108073, 0.43837652206420896, 0.9791687859429253], [0.37537851333618166, 0.5171982659233941, 0.4240745544433594, 0.5800060696072049], [0.37093777656555177, 0.6368573930528428, 0.46719040870666506, 0.7224170260959202], [0.3313652276992798, 0.505009036593967, 0.3773121118545532, 0.5580362108018663], [0.4850620269775391, 0.6537808312310113, 0.5707844734191895, 0.7422096252441406], [0.44458885192871095, 0.8014570448133681, 0.5391969680786133, 0.9749376085069444], [0.44597296714782714, 0.7067598554823133, 0.5251782894134521, 0.8166696336534288], [0.30883541107177737, 0.7512752109103733, 0.4024529933929443, 0.9161632113986545], [0.2959833383560181, 0.6126026577419705, 0.36596319675445554, 0.677711910671658], [0.43532285690307615, 0.884014892578125, 0.49391698837280273, 0.9972827487521702], [0.32147271633148194, 0.5523226420084636, 0.374441933631897, 0.6006682501898871], [0.5064642906188965, 0.5722915225558811, 0.5321310043334961, 0.6121859656439887], [0.36031355857849123, 0.5633324517144097, 0.41484780311584474, 0.6347765604654948]]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    0.32008,     0.85731,     0.43838,     0.97917],\n",
              "       [    0.37538,      0.5172,     0.42407,     0.58001],\n",
              "       [    0.37094,     0.63686,     0.46719,     0.72242],\n",
              "       [    0.33137,     0.50501,     0.37731,     0.55804],\n",
              "       [    0.48506,     0.65378,     0.57078,     0.74221],\n",
              "       [    0.44459,     0.80146,      0.5392,     0.97494],\n",
              "       [    0.44597,     0.70676,     0.52518,     0.81667],\n",
              "       [    0.30884,     0.75128,     0.40245,     0.91616],\n",
              "       [    0.29598,      0.6126,     0.36596,     0.67771],\n",
              "       [    0.43532,     0.88401,     0.49392,     0.99728],\n",
              "       [    0.32147,     0.55232,     0.37444,     0.60067],\n",
              "       [    0.50646,     0.57229,     0.53213,     0.61219],\n",
              "       [    0.36031,     0.56333,     0.41485,     0.63478]])"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make submit"
      ],
      "metadata": {
        "id": "INeK8MXzc_Ko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coco = Coco()\n",
        "coco.add_category(CocoCategory(id=0, name='stone0'))\n",
        "coco.add_category(CocoCategory(id=1, name='stone1'))\n",
        "\n",
        "for path in tqdm(public_paths):\n",
        "    file_name = path.split('/')[-1]\n",
        "    image_id = int(re.findall(r'\\d+', file_name)[0])\n",
        "    coco_image = CocoImage(file_name=file_name, height=1080, width=1920, id=image_id)\n",
        "    \n",
        "    boxes = ensemble_results(path, yolo_models, predictor)\n",
        "    preds = []\n",
        "    for result in boxes:\n",
        "        xmin, ymin, xmax, ymax = result[0], result[1], result[2], result[3]\n",
        "        xmin = int(xmin * 1280)\n",
        "        ymin = int(ymin * 720)\n",
        "        xmax = int(xmax * 1280)\n",
        "        ymax = int(ymax * 720)\n",
        "        preds.append([xmin, ymin, xmax, ymax])\n",
        "\n",
        "    for box in preds:\n",
        "        x_min = int(box[0])\n",
        "        y_min = int(box[1])\n",
        "        width = int(box[2] - x_min)\n",
        "        height = int(box[3]- y_min)\n",
        "        coco_image.add_annotation(\n",
        "            CocoAnnotation(\n",
        "            bbox=[x_min, y_min, width, height],\n",
        "            category_id=1,\n",
        "            category_name='stone1',\n",
        "            image_id=image_id\n",
        "            )\n",
        "        )\n",
        "    coco.add_image(coco_image)\n",
        "\n",
        "save_json(data=coco.json, save_path='kramarenko.json')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqgfZxecgqFc",
        "outputId": "0543151c-91d5-4cb4-c157-ad9a821bdfa8"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:26<00:00,  5.68it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j1arhxmNPEmD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}